{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 - Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Cell 2 - Data Processing Functions\n",
    "def load_svc_file(file_path):\n",
    "    \"\"\"Load and process a single SVC file.\"\"\"\n",
    "    # Skip the first row (count) and read the data\n",
    "    df = pd.read_csv(file_path, skiprows=1, header=None, \n",
    "                     delim_whitespace=True)\n",
    "    \n",
    "    # Assign column names\n",
    "    df.columns = ['x', 'y', 'timestamp', 'pen_status', \n",
    "                 'pressure', 'azimuth', 'altitude']\n",
    "    \n",
    "    # Normalize timestamp to start from 0\n",
    "    df['timestamp'] = (df['timestamp'] - df['timestamp'].min())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_dataset(directory, num_files=None, sequence_length=100):\n",
    "    \"\"\"Process all SVC files in directory and prepare sequences for VRNN.\"\"\"\n",
    "    # Get list of SVC files\n",
    "    svc_files = [f for f in os.listdir(directory) if f.endswith('.svc')]\n",
    "    if num_files:\n",
    "        svc_files = svc_files[:num_files]\n",
    "    \n",
    "    all_sequences = []\n",
    "    scalers = {}\n",
    "    \n",
    "    for file in svc_files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        df = load_svc_file(file_path)\n",
    "        \n",
    "        # Create scalers for each feature\n",
    "        scaler = MinMaxScaler()\n",
    "        normalized_data = scaler.fit_transform(df[['x', 'y', 'timestamp', \n",
    "                                                 'pressure', 'azimuth', 'altitude']])\n",
    "        \n",
    "        # Keep pen_status as binary\n",
    "        normalized_data = np.column_stack((normalized_data, df['pen_status'].values))\n",
    "        \n",
    "        # Create sequences\n",
    "        for i in range(0, len(normalized_data) - sequence_length, sequence_length // 2):\n",
    "            sequence = normalized_data[i:i + sequence_length]\n",
    "            if len(sequence) == sequence_length:\n",
    "                all_sequences.append(sequence)\n",
    "        \n",
    "        scalers[file] = scaler\n",
    "    \n",
    "    return np.array(all_sequences), scalers\n",
    "\n",
    "# Cell 3 - Modified VRNN Cell for Clock Drawing\n",
    "class ClockDrawingVRNNCell(tf.keras.layers.Layer):\n",
    "    def __init__(self, latent_dim, feature_dim, **kwargs):\n",
    "        super(ClockDrawingVRNNCell, self).__init__(**kwargs)\n",
    "        self.latent_dim = latent_dim\n",
    "        self.feature_dim = 7\n",
    "        self.rnn = layers.GRUCell(latent_dim)\n",
    "        \n",
    "        # Required attributes for RNN cells\n",
    "        self.state_size = self.rnn.state_size\n",
    "        self.output_size = (feature_dim, latent_dim, latent_dim, \n",
    "                          latent_dim, latent_dim, latent_dim)\n",
    "        \n",
    "        # Feature extraction\n",
    "        self.feature_extractor = keras.Sequential([\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(latent_dim)\n",
    "        ])\n",
    "        \n",
    "        # Prior network\n",
    "        self.prior_net = keras.Sequential([\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(latent_dim * 2)  # mu and logvar\n",
    "        ])\n",
    "        \n",
    "        # Encoder network\n",
    "        self.encoder_net = keras.Sequential([\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(latent_dim * 2)  # mu and logvar\n",
    "        ])\n",
    "        \n",
    "        # Decoder network\n",
    "        self.decoder_net = keras.Sequential([\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(feature_dim * 2)  # mu and logvar for features\n",
    "        ])\n",
    "\n",
    "    def reparameterize(self, mu, logvar, feature_dim=None):\n",
    "        std = tf.exp(0.5 * logvar)\n",
    "        batch_size = tf.shape(mu)[0]\n",
    "        # Use feature_dim if provided (for decoder output), otherwise use latent_dim\n",
    "        dim = feature_dim if feature_dim is not None else self.latent_dim\n",
    "        eps = tf.random.normal(shape=(batch_size, dim))\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def call(self, inputs, states, training=True):\n",
    "        h_prev = states[0]  # Get previous hidden state\n",
    "        \n",
    "        # Extract features\n",
    "        x_features = self.feature_extractor(inputs)\n",
    "        \n",
    "        # Calculate prior\n",
    "        prior_params = self.prior_net(h_prev)\n",
    "        prior_mu, prior_logvar = tf.split(prior_params, 2, axis=-1)\n",
    "        \n",
    "        # Calculate posterior\n",
    "        encoder_input = tf.concat([x_features, h_prev], axis=-1)\n",
    "        posterior_params = self.encoder_net(encoder_input)\n",
    "        posterior_mu, posterior_logvar = tf.split(posterior_params, 2, axis=-1)\n",
    "        \n",
    "        # Sample latent vector\n",
    "        if training:\n",
    "            z = self.reparameterize(posterior_mu, posterior_logvar)\n",
    "        else:\n",
    "            z = self.reparameterize(prior_mu, prior_logvar)\n",
    "        \n",
    "        # Update RNN state\n",
    "        rnn_input = tf.concat([x_features, z], axis=-1)\n",
    "        h_next_state, _ = self.rnn(rnn_input, [h_prev])\n",
    "        \n",
    "        # Decode\n",
    "        decoder_input = tf.concat([z, h_next_state], axis=-1)\n",
    "        output_params = self.decoder_net(decoder_input)\n",
    "        output_mu, output_logvar = tf.split(output_params, 2, axis=-1)\n",
    "        \n",
    "        # Generate output using the feature dimension\n",
    "        output = self.reparameterize(output_mu, output_logvar, self.feature_dim)\n",
    "        \n",
    "        return (output, z, posterior_mu, prior_mu, \n",
    "                posterior_logvar, prior_logvar), [h_next_state]\n",
    "\n",
    "    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n",
    "        if batch_size is None:\n",
    "            batch_size = tf.shape(inputs)[0]\n",
    "        return [tf.zeros((batch_size, self.latent_dim))]\n",
    "\n",
    "class ClockDrawingVRNNGAN(tf.keras.Model):\n",
    "    def __init__(self, feature_dim, latent_dim, sequence_length, **kwargs):\n",
    "        super(ClockDrawingVRNNGAN, self).__init__(**kwargs)\n",
    "        self.feature_dim = feature_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        # Generator (VRNN)\n",
    "        self.vrnn_cell = ClockDrawingVRNNCell(latent_dim, feature_dim)\n",
    "        self.generator = layers.RNN(self.vrnn_cell, return_sequences=True)\n",
    "        \n",
    "        # Discriminator\n",
    "        self.discriminator = keras.Sequential([\n",
    "            layers.LSTM(32, return_sequences=True),\n",
    "            layers.LSTM(16),\n",
    "            layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        \n",
    "        # Tracking metrics\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "        self.recon_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.gen_loss_tracker,\n",
    "            self.disc_loss_tracker,\n",
    "            self.recon_loss_tracker,\n",
    "            self.kl_loss_tracker\n",
    "        ]\n",
    "    \n",
    "    def compile(self, gen_optimizer, disc_optimizer):\n",
    "        super().compile()\n",
    "        self.gen_optimizer = gen_optimizer\n",
    "        self.disc_optimizer = disc_optimizer\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        # Unpack data\n",
    "        real_sequences = data\n",
    "        batch_size = tf.shape(real_sequences)[0]\n",
    "        \n",
    "        # Train discriminator\n",
    "        with tf.GradientTape() as disc_tape:\n",
    "            # Generate fake sequences\n",
    "            gen_outputs = self.generator(real_sequences[:, :-1, :], training=True)\n",
    "            fake_sequences = gen_outputs[0]\n",
    "            \n",
    "            # Get discriminator predictions\n",
    "            real_preds = self.discriminator(real_sequences, training=True)\n",
    "            fake_preds = self.discriminator(fake_sequences, training=True)\n",
    "            \n",
    "            # Calculate discriminator loss\n",
    "            disc_real_loss = tf.reduce_mean(\n",
    "                tf.keras.losses.binary_crossentropy(tf.ones_like(real_preds), real_preds)\n",
    "            )\n",
    "            disc_fake_loss = tf.reduce_mean(\n",
    "                tf.keras.losses.binary_crossentropy(tf.zeros_like(fake_preds), fake_preds)\n",
    "            )\n",
    "            disc_loss = (disc_real_loss + disc_fake_loss) / 2\n",
    "        \n",
    "        # Apply discriminator gradients\n",
    "        disc_gradients = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "        self.disc_optimizer.apply_gradients(zip(disc_gradients, self.discriminator.trainable_variables))\n",
    "        \n",
    "        # Train generator\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            # Generate fake sequences\n",
    "            gen_outputs = self.generator(real_sequences, training=True)\n",
    "            fake_sequences = gen_outputs[0]\n",
    "            fake_preds = self.discriminator(fake_sequences, training=True)\n",
    "            \n",
    "            # Calculate losses\n",
    "            posterior_mu = gen_outputs[2]\n",
    "            prior_mu = gen_outputs[3]\n",
    "            posterior_logvar = gen_outputs[4]\n",
    "            prior_logvar = gen_outputs[5]\n",
    "            \n",
    "            # KL divergence loss\n",
    "            kl_loss = 0.5 * tf.reduce_mean(\n",
    "                prior_logvar - posterior_logvar + \n",
    "                (tf.exp(posterior_logvar) + tf.square(posterior_mu - prior_mu)) / \n",
    "                tf.exp(prior_logvar) - 1\n",
    "            )\n",
    "            \n",
    "            # Reconstruction loss\n",
    "            recon_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(tf.square(real_sequences - fake_sequences), axis=-1)\n",
    "            )\n",
    "            \n",
    "            # Generator adversarial loss\n",
    "            gen_loss = tf.reduce_mean(\n",
    "                tf.keras.losses.binary_crossentropy(tf.ones_like(fake_preds), fake_preds)\n",
    "            )\n",
    "            \n",
    "            # Total generator loss\n",
    "            total_gen_loss = gen_loss + recon_loss + 0.1 * kl_loss\n",
    "        \n",
    "        # Apply generator gradients\n",
    "        gen_gradients = gen_tape.gradient(total_gen_loss, self.generator.trainable_variables)\n",
    "        self.gen_optimizer.apply_gradients(zip(gen_gradients, self.generator.trainable_variables))\n",
    "        \n",
    "        # Update metrics\n",
    "        self.gen_loss_tracker.update_state(gen_loss)\n",
    "        self.disc_loss_tracker.update_state(disc_loss)\n",
    "        self.recon_loss_tracker.update_state(recon_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        return {\n",
    "            \"gen_loss\": self.gen_loss_tracker.result(),\n",
    "            \"disc_loss\": self.disc_loss_tracker.result(),\n",
    "            \"recon_loss\": self.recon_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "    def generate(self, num_samples):\n",
    "        # Generate random initial input\n",
    "        initial_input = tf.random.normal([num_samples, 1, self.feature_dim])\n",
    "        \n",
    "        # Generate sequence\n",
    "        generated = []\n",
    "        current_input = initial_input\n",
    "        state = [tf.zeros((num_samples, self.latent_dim))]\n",
    "        \n",
    "        for _ in range(self.sequence_length):\n",
    "            outputs, state = self.vrnn_cell(current_input[:, 0], state, training=False)\n",
    "            generated.append(outputs[0])\n",
    "            current_input = tf.expand_dims(outputs[0], 1)\n",
    "        \n",
    "        return tf.concat(generated, axis=1)\n",
    "\n",
    "\n",
    "# Cell 5 - Training Setup and Execution\n",
    "def train_model(data_dir, num_files=None, sequence_length=100, \n",
    "                latent_dim=32, epochs=100, batch_size=32):\n",
    "    # Process data\n",
    "    sequences, scalers = process_dataset(data_dir, num_files, sequence_length)\n",
    "    feature_dim = sequences.shape[-1]\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = ClockDrawingVRNNGAN(\n",
    "        feature_dim=feature_dim,\n",
    "        latent_dim=latent_dim,\n",
    "        sequence_length=sequence_length\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        gen_optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "        disc_optimizer=tf.keras.optimizers.Adam(1e-4)\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        sequences, epochs=epochs, batch_size=batch_size,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='recon_loss',\n",
    "                patience=10,\n",
    "                restore_best_weights=True\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return model, scalers, history\n",
    "\n",
    "# Cell 6 - Generation and Visualization\n",
    "def generate_and_visualize(model, scalers, num_samples=1):\n",
    "    # Generate sequences\n",
    "    generated_sequences = model.generate(num_samples)\n",
    "    generated_sequences = tf.reshape(generated_sequences, [num_samples, -1, model.feature_dim]).numpy()\n",
    "\n",
    "    \n",
    "    # Inverse transform the sequences using the first scaler\n",
    "    scaler = list(scalers.values())[0]\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(num_samples):\n",
    "        sequence = generated_sequences[i]\n",
    "        \n",
    "        # Separate pen_status\n",
    "        pen_status = sequence[:, -1] > 0.5\n",
    "        \n",
    "        # Inverse transform coordinates\n",
    "        coords = sequence[:, :6]  # x, y, timestamp, pressure, azimuth, altitude\n",
    "        coords = scaler.inverse_transform(coords)\n",
    "        \n",
    "        plt.subplot(1, num_samples, i + 1)\n",
    "        plt.scatter(coords[pen_status, 0], -coords[pen_status, 1], \n",
    "                   c='blue', s=1, alpha=0.7, label='On Paper')\n",
    "        plt.scatter(coords[~pen_status, 0], -coords[~pen_status, 1], \n",
    "                   c='red', s=1, alpha=0.7, label='In Air')\n",
    "        plt.title(f'Generated Drawing {i + 1}')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('-y')\n",
    "        plt.legend()\n",
    "        plt.axis('equal')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return generated_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annek\\AppData\\Local\\Temp\\ipykernel_10452\\2944670965.py:15: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(file_path, skiprows=1, header=None,\n",
      "C:\\Users\\annek\\AppData\\Local\\Temp\\ipykernel_10452\\2944670965.py:15: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(file_path, skiprows=1, header=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annek\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\layer.py:391: UserWarning: `build()` was called on layer 'clock_drawing_vrnn_cell_11', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\annek\\AppData\\Local\\Temp\\ipykernel_10452\\2944670965.py\", line 192, in train_step  *\n        gen_outputs = self.generator(real_sequences[:, :-1, :], training=True)\n    File \"C:\\Users\\annek\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling RNN.call().\n    \n    \u001b[1mDimension 1 in both shapes must be equal, but are 7 and 32. Shapes are [?,7] and [?,32].\n    \tFrom merging shape 0 with other shapes. for '{{node rnn_10_1/Cast/x}} = Pack[N=6, T=DT_FLOAT, axis=0](rnn_10_1/strided_slice_3, rnn_10_1/strided_slice_4, rnn_10_1/strided_slice_5, rnn_10_1/strided_slice_6, rnn_10_1/strided_slice_7, rnn_10_1/strided_slice_8)' with input shapes: [?,7], [?,32], [?,32], [?,32], [?,32], [?,32].\u001b[0m\n    \n    Arguments received by RNN.call():\n      • sequences=tf.Tensor(shape=(None, 99, 7), dtype=float32)\n      • initial_state=None\n      • mask=None\n      • training=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Training the model\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m model, scalers, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTask2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequence_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Generate synthetic drawings\u001b[39;00m\n\u001b[0;32m     12\u001b[0m generated_sequences \u001b[38;5;241m=\u001b[39m generate_and_visualize(model, scalers, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "Cell \u001b[1;32mIn[32], line 299\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(data_dir, num_files, sequence_length, latent_dim, epochs, batch_size)\u001b[0m\n\u001b[0;32m    293\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m    294\u001b[0m     gen_optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;241m1e-4\u001b[39m),\n\u001b[0;32m    295\u001b[0m     disc_optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[0;32m    296\u001b[0m )\n\u001b[0;32m    298\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m--> 299\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecon_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, scalers, history\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file75dr0wxf.py:13\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     11\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mshape, (ag__\u001b[38;5;241m.\u001b[39mld(real_sequences),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m disc_tape:\n\u001b[1;32m---> 13\u001b[0m     gen_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_sequences\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     fake_sequences \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(gen_outputs)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     15\u001b[0m     real_preds \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdiscriminator, (ag__\u001b[38;5;241m.\u001b[39mld(real_sequences),), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), fscope)\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\annek\\AppData\\Local\\Temp\\ipykernel_10452\\2944670965.py\", line 192, in train_step  *\n        gen_outputs = self.generator(real_sequences[:, :-1, :], training=True)\n    File \"C:\\Users\\annek\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling RNN.call().\n    \n    \u001b[1mDimension 1 in both shapes must be equal, but are 7 and 32. Shapes are [?,7] and [?,32].\n    \tFrom merging shape 0 with other shapes. for '{{node rnn_10_1/Cast/x}} = Pack[N=6, T=DT_FLOAT, axis=0](rnn_10_1/strided_slice_3, rnn_10_1/strided_slice_4, rnn_10_1/strided_slice_5, rnn_10_1/strided_slice_6, rnn_10_1/strided_slice_7, rnn_10_1/strided_slice_8)' with input shapes: [?,7], [?,32], [?,32], [?,32], [?,32], [?,32].\u001b[0m\n    \n    Arguments received by RNN.call():\n      • sequences=tf.Tensor(shape=(None, 99, 7), dtype=float32)\n      • initial_state=None\n      • mask=None\n      • training=True\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "\n",
    "model, scalers, history = train_model(\n",
    "    data_dir='Task2',\n",
    "    num_files=2,\n",
    "    sequence_length=100,\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Generate synthetic drawings\n",
    "generated_sequences = generate_and_visualize(model, scalers, num_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
