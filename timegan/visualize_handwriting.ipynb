{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process file try/u00033s00001_hw00004.svc: Error tokenizing data. C error: Expected 1 fields in line 2, saw 7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annek\\AppData\\Local\\Temp\\ipykernel_13412\\1192113319.py:13: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(file_path, delim_whitespace=True, header=None)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_handwriting_from_file(file_path):\n",
    "    # Check if the file exists\n",
    "    if not os.path.isfile(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Assuming the file is whitespace-separated and has no header\n",
    "        df = pd.read_csv(file_path, delim_whitespace=True, header=None)\n",
    "        df.columns = ['x', 'y', 'timestamp', 'pen_status', 'pressure', 'azimuth', 'altitude']\n",
    "        \n",
    "        # Separate strokes based on pen status\n",
    "        on_surface = df[df['pen_status'] == 1]\n",
    "        in_air = df[df['pen_status'] == 0]\n",
    "\n",
    "        # Create the plot\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.scatter(on_surface['y'], on_surface['x'], c='k', s=1, alpha=0.7, label='On Surface')  # Navy Blue\n",
    "        plt.scatter(in_air['y'], in_air['x'], c='#eb6f80', s=1, alpha=0.7, label='In Air')\n",
    "        plt.title(f'Handwriting Sample')\n",
    "        plt.xlabel('y')\n",
    "        plt.ylabel('x')\n",
    "        plt.gca().invert_xaxis()\n",
    "        plt.gca().set_aspect('equal')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Could not process file {file_path}: {e}\")\n",
    "\n",
    "# Usage Example:\n",
    "# Specify the path to a single handwriting file\n",
    "file_path = 'try/u00033s00001_hw00004.svc'  # Change this to your actual file path\n",
    "visualize_handwriting_from_file(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original files without corresponding augmented files:\n",
      "collection1u00023s00001_hw00001.svc\n",
      "collection1u00023s00001_hw00005.svc\n",
      "collection1u00035s00001_hw00004.svc\n",
      "collection1u00035s00001_hw00005.svc\n",
      "collection1u00045s00001_hw00004.svc\n",
      "collection1u00045s00001_hw00005.svc\n",
      "u00033s00001_hw00004.svc\n",
      "u00071s00001_hw00005.svc\n",
      "u00077s00001_hw00005.svc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def find_missing_augmented_files(original_folder, augmented_folder):\n",
    "    # Get lists of filenames from both folders\n",
    "    original_files = os.listdir(original_folder)\n",
    "    augmented_files = os.listdir(augmented_folder)\n",
    "    \n",
    "    # Extract the base names of the original files for comparison\n",
    "    original_base_names = {os.path.splitext(file)[0] for file in original_files}\n",
    "    \n",
    "    # Create a set of base names from the augmented files by removing the \"synthetic_\" prefix\n",
    "    augmented_base_names = {\n",
    "        file.replace(\"synthetic_\", \"\").split(\".\")[0]\n",
    "        for file in augmented_files if \"synthetic_\" in file\n",
    "    }\n",
    "    \n",
    "    # Find original files without corresponding augmented files\n",
    "    missing_augmented_files = [\n",
    "        file for file in original_files\n",
    "        if os.path.splitext(file)[0] not in augmented_base_names\n",
    "    ]\n",
    "    \n",
    "    # Output the missing files\n",
    "    print(\"Original files without corresponding augmented files:\")\n",
    "    for missing_file in missing_augmented_files:\n",
    "        print(missing_file)\n",
    "    \n",
    "    return missing_augmented_files\n",
    "\n",
    "# Example usage\n",
    "original_folder = \"../all_datasets/emothaw\"\n",
    "augmented_folder = \"output\"\n",
    "missing_files = find_missing_augmented_files(original_folder, augmented_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
